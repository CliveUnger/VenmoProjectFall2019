{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful links for processing graphs on pyspark:\n",
    "\n",
    "https://docs.databricks.com/spark/latest/graph-analysis/graphframes/user-guide-python.html\n",
    "\n",
    "https://graphframes.github.io/graphframes/docs/_site/user-guide.html\n",
    "\n",
    "https://pysparktutorial.blogspot.com/2017/10/graphframes-pyspark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql.functions import col, size\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  2.4.4\n",
      "defaultParallelism:  44\n",
      "Spark WebURLL  http://c251-102.wrangler.tacc.utexas.edu:4040\n"
     ]
    }
   ],
   "source": [
    "# Start spark in local mode using 54gb of memory\n",
    "# local mode only runs on a single node, but it will utilize all cores (We have 48!)\n",
    "conf = SparkConf().setAppName(\"test\") \\\n",
    "    .setMaster(\"local[44]\") \\\n",
    "    .set('spark.driver.memory','54g') \\\n",
    "    .set('spark.jars.packages', 'graphframes:graphframes:0.7.0-spark2.4-s_2.11')\n",
    "#.setMaster(\"yarn\") # this is used when we run on hadoop, ignore for now\n",
    "\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "print(\"Spark Version: \", sc.version)\n",
    "print(\"defaultParallelism: \", sc.defaultParallelism)\n",
    "print(\"Spark WebURLL \", sc.uiWebUrl) # you can view running jobs here, but I am only able to connect to it via VNC rn, maybe SSH tunneling will fix this? idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.jars.packages', 'graphframes:graphframes:0.7.0-spark2.4-s_2.11'),\n",
       " ('spark.app.name', 'test'),\n",
       " ('spark.driver.memory', '54g'),\n",
       " ('spark.files',\n",
       "  'file:///home/06271/cju256/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///home/06271/cju256/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.local.dir', '/data/06271/cju256/temp'),\n",
       " ('spark.master', 'local[44]'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/06271/cju256/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,/home/06271/cju256/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.driver.port', '38377'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1573517162464'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///home/06271/cju256/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///home/06271/cju256/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.jars',\n",
       "  'file:///home/06271/cju256/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///home/06271/cju256/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.driver.host', 'c251-102.wrangler.tacc.utexas.edu'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll() # See all the current Spark configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "# load data from the json file (we can also do the csv when we have it)\n",
    "\n",
    "schema_json = sqlContext.read.text(\"/data/06271/cju256/flat.schema\").first()[0]\n",
    "schema = StructType.fromJson(json.loads(schema_json))\n",
    "\n",
    "flat_df = sqlContext.read.json('/data/06271/cju256/ut_venmo_2018_flat.json', schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_subset_path = '/data/06271/cju256/nodes.json'\n",
    "edges_subset_path = '/data/06271/cju256/edges.json'\n",
    "\n",
    "nodes_subset = sqlContext.read.json(nodes_subset_path)\n",
    "edges_subset = sqlContext.read.json(edges_subset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- about: string (nullable = true)\n",
      " |-- cancelled: boolean (nullable = true)\n",
      " |-- date_created: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- external_id: string (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- is_business: boolean (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_friends: long (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- picture: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes_subset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- comments_count: long (nullable = true)\n",
      " |-- created_time: string (nullable = true)\n",
      " |-- dst: long (nullable = true)\n",
      " |-- likes_count: long (nullable = true)\n",
      " |-- mentions_count: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- payment_id: long (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- src: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- unix_time: long (nullable = true)\n",
      " |-- updated_time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges_subset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_subset.select('id','friends', 'num_friends').filter('friends == true').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "just_nodes = nodes_subset.withColumn(\"id_string\", col('id').cast(IntegerType())).drop('id').withColumnRenamed(\"id_string\",'id')\n",
    "just_edges = edges_subset \\\n",
    "                .withColumn(\"src_string\", col('src').cast(IntegerType())).drop('src').withColumnRenamed(\"src_string\",'src') \\\n",
    "                .withColumn(\"dst_string\", col('dst').cast(IntegerType())).drop('dst').withColumnRenamed(\"dst_string\",'dst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_edges = just_edges.filter('dst is not null')\n",
    "\n",
    "just_edges.filter('dst is null').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "src_2 = udf(lambda src, dst, typ: dst if typ == 'charge' else src , LongType())\n",
    "dst_2 = udf(lambda src, dst, typ: src if typ == 'charge' else dst , LongType())\n",
    "\n",
    "edges2 = just_edges.select('src', 'dst', 'type')\n",
    "\n",
    "edges3 = edges2.withColumn(\"src2\", src_2(edges2.src, edges2.dst, edges2.type))\n",
    "edges4 = edges3.withColumn('dst2', dst_2(edges2.src, edges2.dst, edges2.type))\n",
    "\n",
    "money_flow_edges = edges4.selectExpr(\"src2 as src\", \"dst2 as dst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|   src|   dst|\n",
      "+------+------+\n",
      "| 33632| 59741|\n",
      "|111497|110891|\n",
      "| 34421| 22792|\n",
      "| 85649|107484|\n",
      "| 26924| 34907|\n",
      "|115128|115131|\n",
      "| 74104| 65588|\n",
      "| 60063| 71313|\n",
      "| 29674| 22222|\n",
      "|116523|125011|\n",
      "| 73816| 27407|\n",
      "| 65739| 53702|\n",
      "| 43575| 28429|\n",
      "|130287|130290|\n",
      "|116185|128330|\n",
      "|129335|127245|\n",
      "| 64514| 63739|\n",
      "|135785| 77747|\n",
      "|131328|126429|\n",
      "|126227|123908|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "money_flow_edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- src: long (nullable = true)\n",
      " |-- dst: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "money_flow_edges.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131705390"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_flow_edges.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341309788"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_flow_edges.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- src: long (nullable = true)\n",
      " |-- dst: long (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "money_flow_distinct = money_flow_edges.groupBy('src', 'dst').count()\n",
    "money_flow_distinct.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|    src|    dst|count|\n",
      "+-------+-------+-----+\n",
      "| 164496| 277424|   34|\n",
      "| 445173| 452915|  408|\n",
      "| 299233| 247051|   94|\n",
      "| 645631| 275235|    8|\n",
      "| 982986| 925688|    3|\n",
      "| 248879| 540594|  132|\n",
      "| 370468| 419610|    6|\n",
      "| 210829| 178313|   28|\n",
      "| 551463| 732586|    2|\n",
      "|1500565|1451912|    1|\n",
      "| 150386| 544205|    8|\n",
      "| 253680| 361844|    8|\n",
      "| 744023| 582098|   34|\n",
      "|1075344|1246158|   16|\n",
      "|1219636|2284421|   26|\n",
      "|1595150| 781187|    1|\n",
      "| 400927|1085247|   15|\n",
      "| 966746| 966719|   38|\n",
      "| 624112|1560925|  101|\n",
      "|2486382| 243326|    1|\n",
      "+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "money_flow_distinct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(dst)|\n",
      "+--------+\n",
      "|       2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result = money_flow_distinct.select([F.min(\"dst\")])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_flow_distinct.coalesce(1).write.format('csv').save('/data/06271/cju256/money_flow_weighted_edgelist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some time math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, LongType, TimestampType\n",
    "\n",
    "just_edges = just_edges.withColumn('epoch_time', col('unix_time').cast(TimestampType())) \\\n",
    "                .withColumn(\"created_time_tmp\", col('created_time').cast(TimestampType())).drop('created_time').withColumnRenamed('created_time_tmp', 'created_time') \\\n",
    "                .withColumn(\"updated_time_tmp\", col('updated_time').cast(TimestampType())).drop('updated_time').withColumnRenamed('updated_time_tmp', 'updated_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+-------------------+-------------------+-------------------+---------+\n",
      "|   src|   dst|   type|         epoch_time|       updated_time|       created_time| duration|\n",
      "+------+------+-------+-------------------+-------------------+-------------------+---------+\n",
      "|142212| 93793|payment|2012-10-02 17:16:55|2013-03-18 12:58:30|2012-10-02 17:16:55| 14413295|\n",
      "|124108|124107|payment|2012-12-31 05:28:01|2012-12-31 05:31:35|2012-12-31 05:28:01|      214|\n",
      "|212641|213840|payment|2013-02-26 21:13:58|2013-02-26 21:34:08|2013-02-26 21:13:58|     1210|\n",
      "|145349|145266|payment|2013-03-18 09:31:55|2013-03-19 07:28:37|2013-03-18 09:31:55|    79002|\n",
      "|247500|251943|payment|2013-03-31 19:27:28|2013-04-05 06:49:03|2013-03-31 19:27:28|   386495|\n",
      "|174121|148636|payment|2013-04-11 16:02:14|2013-04-11 16:59:34|2013-04-11 16:02:14|     3440|\n",
      "| 46041| 48431|payment|2013-04-30 00:04:17|2013-05-01 08:12:52|2013-04-30 00:04:17|   115715|\n",
      "|290657|143827|payment|2013-05-03 20:30:47|2013-05-04 21:31:18|2013-05-03 20:30:47|    90031|\n",
      "|277424|164496| charge|2013-05-07 15:14:33|2013-05-22 14:24:32|2013-05-07 15:14:33|  1292999|\n",
      "| 66872| 57385|payment|2013-05-26 20:30:20|2017-10-13 21:51:13|2013-05-26 20:30:20|138331253|\n",
      "|314188| 48430|payment|2013-05-25 17:55:55|2013-06-01 10:29:25|2013-05-25 17:55:55|   578010|\n",
      "|190539|190552| charge|2013-06-03 11:36:16|2013-06-13 22:07:36|2013-06-03 11:36:16|   901880|\n",
      "|225775|212487|payment|2013-06-26 12:20:46|2013-07-06 03:28:55|2013-06-26 12:20:46|   832089|\n",
      "|371990|355310|payment|2013-07-07 13:31:22|2013-07-07 13:35:48|2013-07-07 13:31:22|      266|\n",
      "|277450|345475|payment|2013-07-15 15:42:25|2013-07-15 19:53:51|2013-07-15 15:42:25|    15086|\n",
      "|286303|187212|payment|2013-07-19 08:30:33|2013-07-19 08:58:33|2013-07-19 08:30:33|     1680|\n",
      "|313246|310110|payment|2013-07-20 16:44:12|2013-07-20 17:38:09|2013-07-20 16:44:12|     3237|\n",
      "|404848|425509|payment|2013-08-08 11:36:32|2013-08-08 11:40:10|2013-08-08 11:36:32|      218|\n",
      "|182273|175515|payment|2013-08-04 21:38:55|2013-08-05 13:10:45|2013-08-04 21:38:55|    55910|\n",
      "|256495|130236|payment|2013-08-13 11:29:50|2013-08-13 11:53:33|2013-08-13 11:29:50|     1423|\n",
      "+------+------+-------+-------------------+-------------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "timeFmt = \"yyyy-MM-dd'T'HH:mm:ss.SSS\"\n",
    "timeDiff = (F.unix_timestamp('updated_time', format=timeFmt)\n",
    "            - F.unix_timestamp('created_time', format=timeFmt))\n",
    "just_edges = just_edges.withColumn(\"duration\", timeDiff)\n",
    "\n",
    "just_edges.filter('duration > 0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------------------+-------------------+-------------------+---------+\n",
      "|   src|   dst|  type|         epoch_time|       updated_time|       created_time| duration|\n",
      "+------+------+------+-------------------+-------------------+-------------------+---------+\n",
      "| 46015| 25927|charge|2012-07-02 13:02:24|2018-05-09 09:52:17|2012-07-02 13:02:24|184625393|\n",
      "| 75333| 82755|charge|2012-10-06 19:27:33|2018-03-08 18:34:22|2012-10-06 19:27:33|170986009|\n",
      "|156709|156664|charge|2012-10-24 04:07:37|2018-03-13 07:24:27|2012-10-24 04:07:37|169874210|\n",
      "|  3949|166144|charge|2012-12-13 06:56:27|2018-01-07 15:23:26|2012-12-13 06:56:27|159956819|\n",
      "|328576|304905|charge|2013-06-15 16:09:21|2018-05-25 08:24:07|2013-06-15 11:09:21|155942086|\n",
      "|164574|108062|charge|2012-10-25 00:38:55|2017-09-28 12:33:28|2012-10-25 00:38:55|155476473|\n",
      "|134105|243520|charge|2013-05-07 17:26:39|2018-03-24 22:23:44|2013-05-07 17:26:39|153982625|\n",
      "|129591|131761|charge|2013-04-27 00:32:14|2018-03-12 13:20:12|2013-04-27 00:32:14|153838078|\n",
      "| 82495| 88637|charge|2012-04-05 03:21:12|2017-02-01 15:21:50|2012-04-05 03:21:12|152370038|\n",
      "|187298|187367|charge|2012-12-19 08:35:58|2017-10-07 23:05:35|2012-12-19 08:35:58|151507777|\n",
      "|163479|168444|charge|2012-11-27 23:51:32|2017-09-06 11:57:30|2012-11-27 23:51:32|150635158|\n",
      "|193266|174482|charge|2013-06-29 18:47:22|2018-03-30 14:23:04|2013-06-29 18:47:22|149888142|\n",
      "|362573| 71019|charge|2013-07-09 18:47:00|2018-04-03 15:46:42|2013-07-09 18:47:00|149374782|\n",
      "|117301|216562|charge|2013-02-26 22:39:55|2017-11-19 13:22:45|2013-02-26 22:39:55|149179370|\n",
      "|235504|235607|charge|2013-03-09 20:09:10|2017-11-28 17:16:18|2013-03-09 20:09:10|149029628|\n",
      "|327614|293229|charge|2013-09-10 18:36:46|2018-05-30 15:54:12|2013-09-10 13:36:46|148875446|\n",
      "|135988|144411|charge|2012-09-05 22:04:48|2017-05-14 07:36:04|2012-09-05 22:04:48|147864676|\n",
      "|152539|196637|charge|2013-01-07 14:30:51|2017-09-01 00:07:41|2013-01-07 14:30:51|146651810|\n",
      "|346461|346722|charge|2013-08-18 15:57:18|2018-04-11 13:03:06|2013-08-18 10:57:18|146628348|\n",
      "|346722|346461|charge|2013-08-25 10:57:17|2018-04-11 13:03:14|2013-08-25 10:57:17|146023557|\n",
      "+------+------+------+-------------------+-------------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "just_edges.filter(\"duration > 0\").orderBy('duration', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10794463"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_edges.filter(\"duration > 86400\").orderBy('duration', ascending=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphFrame(v:[id: bigint, about: string ... 13 more fields], e:[src: bigint, dst: bigint ... 11 more fields])\n"
     ]
    }
   ],
   "source": [
    "g = GraphFrame(nodes_subset, edges_subset)\n",
    "print(g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphFrame(v:[id: int, about: string ... 13 more fields], e:[src: int, dst: int ... 11 more fields])\n"
     ]
    }
   ],
   "source": [
    "g = GraphFrame(just_nodes, just_edges)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[about: string, cancelled: boolean, date_created: string, email: string, external_id: string, firstname: string, friends: string, is_business: boolean, lastname: string, name: string, num_friends: bigint, phone: string, picture: string, username: string, id: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: string, comments_count: bigint, created_time: string, likes_count: bigint, mentions_count: bigint, message: string, payment_id: bigint, permalink: string, type: string, unix_time: bigint, updated_time: string, src: int, dst: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(g.vertices)\n",
    "display(g.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:  23133264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a191f746e0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nodes: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Edges: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/intel18/python3/3.7.0/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Nodes: \", g.vertices.count())\n",
    "print(\"Edges: \", g.edges.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|      id|degree|\n",
      "+--------+------+\n",
      "|    null|  2846|\n",
      "|  820531|   696|\n",
      "| 1002607|   100|\n",
      "|  351854|    39|\n",
      "|18765786|    31|\n",
      "| 2367489|    28|\n",
      "| 9094113|    24|\n",
      "| 6655326|    22|\n",
      "| 4943840|    20|\n",
      "| 1667966|    19|\n",
      "|19189246|    18|\n",
      "| 8767908|    18|\n",
      "| 1307021|    17|\n",
      "| 7144810|    16|\n",
      "| 2723711|    15|\n",
      "| 6445290|    15|\n",
      "|  206476|    15|\n",
      "|18654246|    14|\n",
      "| 3475962|    14|\n",
      "| 3943041|    14|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.degrees.orderBy('degree', ascending=False).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results = g.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.select(\"id\", \"pagerank\").orderBy('pagerank', ascending=False).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n",
    "motifs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DST',\n",
       " 'ID',\n",
       " 'SRC',\n",
       " '_ATTR',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_edges',\n",
       " '_jvm_gf_api',\n",
       " '_jvm_graph',\n",
       " '_sc',\n",
       " '_sqlContext',\n",
       " '_vertices',\n",
       " 'aggregateMessages',\n",
       " 'bfs',\n",
       " 'cache',\n",
       " 'connectedComponents',\n",
       " 'degrees',\n",
       " 'dropIsolatedVertices',\n",
       " 'edges',\n",
       " 'filterEdges',\n",
       " 'filterVertices',\n",
       " 'find',\n",
       " 'inDegrees',\n",
       " 'labelPropagation',\n",
       " 'outDegrees',\n",
       " 'pageRank',\n",
       " 'parallelPersonalizedPageRank',\n",
       " 'persist',\n",
       " 'shortestPaths',\n",
       " 'stronglyConnectedComponents',\n",
       " 'svdPlusPlus',\n",
       " 'triangleCount',\n",
       " 'triplets',\n",
       " 'unpersist',\n",
       " 'vertices']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = g.triangleCount()\n",
    "#triangles.select('id', 'count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f839806f8132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Search for pairs of vertices with edges in both directions between them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmotifs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(a)-[e]->(b); (b)-[e2]->(c)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmotifs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# More complex queries can be expressed by applying filters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/spark-2.4.4-bin-hadoop2.6/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/intel18/python3/3.7.0/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search for pairs of vertices with edges in both directions between them.\n",
    "motifs = g.find(\"(a)-[e]->(b); (b)-[e2]->(c)\")\n",
    "motifs.show()\n",
    "\n",
    "# More complex queries can be expressed by applying filters.\n",
    "motifs.filter(\"a.id != c.id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs.filter(\"a.id != c.id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_links = g.degrees.withColumn('links', col('degree') * ( col('degree') - 1))\n",
    "#degree_links.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_coef = triangles.select(\"id\", \"count\").join(degree_links, on='id')\n",
    "#clustering_coef.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-----+--------------------+\n",
      "|      id|count|degree|links|     clustering_coef|\n",
      "+--------+-----+------+-----+--------------------+\n",
      "|10000108|    3|    15|  210|0.014285714285714285|\n",
      "|10000172|   63|    47| 2162|0.029139685476410732|\n",
      "|10000304|    1|     8|   56|0.017857142857142856|\n",
      "|10000454|    4|    29|  812|0.004926108374384...|\n",
      "|10000472|    1|     9|   72|0.013888888888888888|\n",
      "|10000591|   33|   124|15252|0.002163650668764...|\n",
      "|10000670|   38|    35| 1190|0.031932773109243695|\n",
      "|10000720|   22|   111|12210|0.001801801801801...|\n",
      "|10000989|  568|   291|84390|0.006730655290911245|\n",
      "|  100010|    0|     5|   20|                 0.0|\n",
      "|10001989|    3|     7|   42| 0.07142857142857142|\n",
      "|10002011|   10|    44| 1892|0.005285412262156448|\n",
      "|10002280|   58|   105|10920|0.005311355311355312|\n",
      "| 1000240|   55|   172|29412|0.001869985040119679|\n",
      "| 1000280|   88|   260|67340|0.001306801306801...|\n",
      "|10002811|    2|     3|    6|  0.3333333333333333|\n",
      "|10003360|    2|    25|  600|0.003333333333333...|\n",
      "|10003366|    0|     5|   20|                 0.0|\n",
      "|10004759|    3|    28|  756|0.003968253968253968|\n",
      "|10004786|    0|     1|    0|                null|\n",
      "+--------+-----+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_coef = clustering_coef.withColumn(\"clustering_coef\", col('count') / col('links'))\n",
    "clustering_coef.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|summary|                  id|             count|            degree|             links|     clustering_coef|\n",
      "+-------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|  count|            23133263|          23133263|          23133263|          23133263|            18500705|\n",
      "|   mean|1.6629731765690641E7|14.130407759597079|29.550124165363098|4932.8911883291175|0.021464098934943332|\n",
      "| stddev|1.0336052173548613E7|61.334882678439754|  77.1093475591475| 483843.3696589889|  0.0642531063456038|\n",
      "|    min|                  10|                 0|                 1|                 0|                 0.0|\n",
      "|    max|             9999999|             21038|            212126|        2047554790|                 0.5|\n",
      "+-------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_coef.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-----+---------------+\n",
      "|      id|count|degree|links|clustering_coef|\n",
      "+--------+-----+------+-----+---------------+\n",
      "|10358879|    1|     2|    2|            0.5|\n",
      "|10865863|    6|     4|   12|            0.5|\n",
      "|10480795|    1|     2|    2|            0.5|\n",
      "|10157554|    1|     2|    2|            0.5|\n",
      "|10594781|    1|     2|    2|            0.5|\n",
      "|10605938|    1|     2|    2|            0.5|\n",
      "|10189165|    1|     2|    2|            0.5|\n",
      "|10621410|    1|     2|    2|            0.5|\n",
      "|10254885|    1|     2|    2|            0.5|\n",
      "|10667695|    1|     2|    2|            0.5|\n",
      "|10284320|    1|     2|    2|            0.5|\n",
      "|10686037|    1|     2|    2|            0.5|\n",
      "|10122283|    1|     2|    2|            0.5|\n",
      "|10694655|    1|     2|    2|            0.5|\n",
      "|10499540|    1|     2|    2|            0.5|\n",
      "|10725346|    1|     2|    2|            0.5|\n",
      "|10837788|    1|     2|    2|            0.5|\n",
      "|10733158|    1|     2|    2|            0.5|\n",
      "|10269066|    1|     2|    2|            0.5|\n",
      "|10761553|    1|     2|    2|            0.5|\n",
      "+--------+-----+------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_coef.orderBy('clustering_coef', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can i run two jupyer notebook jobs at onces , i.e sbatch job.jupyter twice \n",
    "\n",
    "# is spark run seperately each time? or does it share spark resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
