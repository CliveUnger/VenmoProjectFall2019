{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql.functions import col, size\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  2.4.4\n",
      "defaultParallelism:  48\n",
      "Spark WebURLL  http://c251-132.wrangler.tacc.utexas.edu:4040\n"
     ]
    }
   ],
   "source": [
    "# Start spark in local mode using 100gb of memory\n",
    "# local mode only runs on a single node, but it will utilize all cores (We have 48!)\n",
    "conf = SparkConf().setAppName(\"test\").set('spark.driver.memory','64g')\n",
    "#.setMaster(\"yarn\") # this is used when we run on hadoop, ignore for now\n",
    "\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "print(\"Spark Version: \", sc.version)\n",
    "print(\"defaultParallelism: \", sc.defaultParallelism)\n",
    "print(\"Spark WebURLL \", sc.uiWebUrl) # you can view running jobs here, but I am only able to connect to it via VNC rn, maybe SSH tunneling will fix this? idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1572982312923'),\n",
       " ('spark.driver.host', 'c251-132.wrangler.tacc.utexas.edu'),\n",
       " ('spark.driver.port', '36358'),\n",
       " ('spark.driver.memory', '64g'),\n",
       " ('spark.app.name', 'test'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.local.dir', '/data/06271/cju256/temp'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll() # See all the current Spark configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "# load data from the json file (we can also do the csv when we have it)\n",
    "\n",
    "schema_json = sqlContext.read.text(\"/data/06271/cju256/flat.schema\").first()[0]\n",
    "schema = StructType.fromJson(json.loads(schema_json))\n",
    "\n",
    "flat_df = sqlContext.read.json('/data/06271/cju256/ut_venmo_2018_flat.json', schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- actor_about: string (nullable = true)\n",
      " |-- actor_cancelled: boolean (nullable = true)\n",
      " |-- actor_date_created: string (nullable = true)\n",
      " |-- actor_email: string (nullable = true)\n",
      " |-- actor_external_id: string (nullable = true)\n",
      " |-- actor_firstname: string (nullable = true)\n",
      " |-- actor_friends: string (nullable = true)\n",
      " |-- actor_id: long (nullable = true)\n",
      " |-- actor_is_business: boolean (nullable = true)\n",
      " |-- actor_lastname: string (nullable = true)\n",
      " |-- actor_name: string (nullable = true)\n",
      " |-- actor_num_friends: long (nullable = true)\n",
      " |-- actor_phone: string (nullable = true)\n",
      " |-- actor_picture: string (nullable = true)\n",
      " |-- actor_username: string (nullable = true)\n",
      " |-- comments_count: long (nullable = true)\n",
      " |-- created_time: string (nullable = true)\n",
      " |-- likes_count: long (nullable = true)\n",
      " |-- mentions_count: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- payment_id: long (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- target_about: string (nullable = true)\n",
      " |-- target_cancelled: boolean (nullable = true)\n",
      " |-- target_date_created: string (nullable = true)\n",
      " |-- target_email: string (nullable = true)\n",
      " |-- target_external_id: string (nullable = true)\n",
      " |-- target_firstname: string (nullable = true)\n",
      " |-- target_friends: string (nullable = true)\n",
      " |-- target_id: long (nullable = true)\n",
      " |-- target_is_business: boolean (nullable = true)\n",
      " |-- target_lastname: string (nullable = true)\n",
      " |-- target_name: string (nullable = true)\n",
      " |-- target_num_friends: long (nullable = true)\n",
      " |-- target_phone: string (nullable = true)\n",
      " |-- target_picture: string (nullable = true)\n",
      " |-- target_type: string (nullable = true)\n",
      " |-- target_username: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- unix_time: long (nullable = true)\n",
      " |-- updated_time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the schema of the json\n",
    "flat_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
