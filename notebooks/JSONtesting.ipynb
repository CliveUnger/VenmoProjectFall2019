{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql.functions import col, size\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  2.4.4\n",
      "defaultParallelism:  48\n",
      "Spark WebURLL  http://c251-132.wrangler.tacc.utexas.edu:4040\n"
     ]
    }
   ],
   "source": [
    "# Start spark in local mode using 100gb of memory\n",
    "# local mode only runs on a single node, but it will utilize all cores (We have 48!)\n",
    "conf = SparkConf().setAppName(\"test\").set('spark.driver.memory','64g')\n",
    "#.setMaster(\"yarn\") # this is used when we run on hadoop, ignore for now\n",
    "\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "print(\"Spark Version: \", sc.version)\n",
    "print(\"defaultParallelism: \", sc.defaultParallelism)\n",
    "print(\"Spark WebURLL \", sc.uiWebUrl) # you can view running jobs here, but I am only able to connect to it via VNC rn, maybe SSH tunneling will fix this? idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1572982312923'),\n",
       " ('spark.driver.host', 'c251-132.wrangler.tacc.utexas.edu'),\n",
       " ('spark.driver.port', '36358'),\n",
       " ('spark.driver.memory', '64g'),\n",
       " ('spark.app.name', 'test'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.local.dir', '/data/06271/cju256/temp'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll() # See all the current Spark configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "# load data from the json file (we can also do the csv when we have it)\n",
    "\n",
    "schema_json = sqlContext.read.text(\"/data/06271/cju256/flat.schema\").first()[0]\n",
    "schema = StructType.fromJson(json.loads(schema_json))\n",
    "\n",
    "flat_df = sqlContext.read.json('/data/06271/cju256/ut_venmo_2018_flat.json', schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- actor_about: string (nullable = true)\n",
      " |-- actor_cancelled: boolean (nullable = true)\n",
      " |-- actor_date_created: string (nullable = true)\n",
      " |-- actor_email: string (nullable = true)\n",
      " |-- actor_external_id: string (nullable = true)\n",
      " |-- actor_firstname: string (nullable = true)\n",
      " |-- actor_friends: string (nullable = true)\n",
      " |-- actor_id: long (nullable = true)\n",
      " |-- actor_is_business: boolean (nullable = true)\n",
      " |-- actor_lastname: string (nullable = true)\n",
      " |-- actor_name: string (nullable = true)\n",
      " |-- actor_num_friends: long (nullable = true)\n",
      " |-- actor_phone: string (nullable = true)\n",
      " |-- actor_picture: string (nullable = true)\n",
      " |-- actor_username: string (nullable = true)\n",
      " |-- comments_count: long (nullable = true)\n",
      " |-- created_time: string (nullable = true)\n",
      " |-- likes_count: long (nullable = true)\n",
      " |-- mentions_count: long (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- payment_id: long (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- target_about: string (nullable = true)\n",
      " |-- target_cancelled: boolean (nullable = true)\n",
      " |-- target_date_created: string (nullable = true)\n",
      " |-- target_email: string (nullable = true)\n",
      " |-- target_external_id: string (nullable = true)\n",
      " |-- target_firstname: string (nullable = true)\n",
      " |-- target_friends: string (nullable = true)\n",
      " |-- target_id: long (nullable = true)\n",
      " |-- target_is_business: boolean (nullable = true)\n",
      " |-- target_lastname: string (nullable = true)\n",
      " |-- target_name: string (nullable = true)\n",
      " |-- target_num_friends: long (nullable = true)\n",
      " |-- target_phone: string (nullable = true)\n",
      " |-- target_picture: string (nullable = true)\n",
      " |-- target_type: string (nullable = true)\n",
      " |-- target_username: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- unix_time: long (nullable = true)\n",
      " |-- updated_time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the schema of the json\n",
    "flat_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, LongType, TimestampType\n",
    "\n",
    "flat_df = flat_df.withColumn('epoch_time', col('unix_time').cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------------+------------------+-----------+-----------------+---------------+-------------+--------+-----------------+--------------+----------+-----------------+-----------+-------------+--------------+--------------+------------+-----------+--------------+-------+----------+---------+------------+----------------+-------------------+------------+------------------+----------------+--------------+---------+------------------+---------------+-----------+------------------+------------+--------------+-----------+---------------+----+---------+------------+----------+----------+\n",
      "|_id|actor_about|actor_cancelled|actor_date_created|actor_email|actor_external_id|actor_firstname|actor_friends|actor_id|actor_is_business|actor_lastname|actor_name|actor_num_friends|actor_phone|actor_picture|actor_username|comments_count|created_time|likes_count|mentions_count|message|payment_id|permalink|target_about|target_cancelled|target_date_created|target_email|target_external_id|target_firstname|target_friends|target_id|target_is_business|target_lastname|target_name|target_num_friends|target_phone|target_picture|target_type|target_username|type|unix_time|updated_time|epoch_time|year_month|\n",
      "+---+-----------+---------------+------------------+-----------+-----------------+---------------+-------------+--------+-----------------+--------------+----------+-----------------+-----------+-------------+--------------+--------------+------------+-----------+--------------+-------+----------+---------+------------+----------------+-------------------+------------+------------------+----------------+--------------+---------+------------------+---------------+-----------+------------------+------------+--------------+-----------+---------------+----+---------+------------+----------+----------+\n",
      "+---+-----------+---------------+------------------+-----------+-----------------+---------------+-------------+--------+-----------------+--------------+----------+-----------------+-----------+-------------+--------------+--------------+------------+-----------+--------------+-------+----------+---------+------------+----------------+-------------------+------------+------------------+----------------+--------------+---------+------------------+---------------+-----------+------------------+------------+--------------+-----------+---------------+----+---------+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "flat_df.select('*', F.date_format('epoch_time', \"yyyy-MM\").alias('year_month')) \\\n",
    "            .filter(col('year_month') == F.lit('2018-05')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  month|   count|\n",
      "+-------+--------+\n",
      "|2012-03|      15|\n",
      "|2012-04|    3280|\n",
      "|2012-05|    4433|\n",
      "|2012-06|    4756|\n",
      "|2012-07|    5571|\n",
      "|2012-08|    7338|\n",
      "|2012-09|    9769|\n",
      "|2012-10|   11965|\n",
      "|2012-11|   13677|\n",
      "|2012-12|   16453|\n",
      "|2013-01|   21337|\n",
      "|2013-02|   25457|\n",
      "|2013-03|   33211|\n",
      "|2013-04|   40643|\n",
      "|2013-05|   48467|\n",
      "|2013-06|   50822|\n",
      "|2013-07|   64736|\n",
      "|2013-08|   88611|\n",
      "|2013-09|  120736|\n",
      "|2013-10|  147528|\n",
      "|2013-11|  173434|\n",
      "|2013-12|  192545|\n",
      "|2014-01|  256247|\n",
      "|2014-02|  301696|\n",
      "|2014-03|  410951|\n",
      "|2014-04|  464851|\n",
      "|2014-05|  530547|\n",
      "|2014-06|  524249|\n",
      "|2014-07|  589398|\n",
      "|2014-08|  733758|\n",
      "|2014-09|  901403|\n",
      "|2014-10| 1049696|\n",
      "|2014-11| 1120404|\n",
      "|2014-12| 1156727|\n",
      "|2015-01| 1412554|\n",
      "|2015-02| 1568348|\n",
      "|2015-03| 1962782|\n",
      "|2015-04| 2128499|\n",
      "|2015-05| 2312411|\n",
      "|2015-06| 2040899|\n",
      "|2015-07| 2245847|\n",
      "|2015-08| 2642943|\n",
      "|2015-09| 3161513|\n",
      "|2015-10| 3567102|\n",
      "|2015-11| 3528311|\n",
      "|2015-12| 3602472|\n",
      "|2016-01| 4322864|\n",
      "|2016-02| 4691546|\n",
      "|2016-03| 5384113|\n",
      "|2016-04| 6004204|\n",
      "|2016-05| 5873658|\n",
      "|2016-06| 5285186|\n",
      "|2016-07| 5819564|\n",
      "|2016-08| 6606997|\n",
      "|2016-09| 7926135|\n",
      "|2016-10| 8837559|\n",
      "|2016-11| 8391221|\n",
      "|2016-12| 8762606|\n",
      "|2017-01| 9543802|\n",
      "|2017-02|10198856|\n",
      "|2017-03|12172720|\n",
      "|2017-04|12337903|\n",
      "|2017-05|11904134|\n",
      "|2017-06|10988529|\n",
      "|2017-07|11743704|\n",
      "|2017-08|13415316|\n",
      "|2017-09|15363677|\n",
      "|2017-10|16379273|\n",
      "|2017-11|15309223|\n",
      "|2017-12|15910025|\n",
      "|2018-01|16423224|\n",
      "|2018-02|15860226|\n",
      "|2018-03|18825538|\n",
      "|2018-04|15020548|\n",
      "|2018-07|  152113|\n",
      "|2018-08| 3528150|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year_month = flat_df.select(F.date_format('epoch_time','yyyy-MM').alias('month')).groupby('month').count().persist()\n",
    "year_month.orderBy('month').show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             message|\n",
      "+--------------------+\n",
      "|             for tea|\n",
      "|    for contribution|\n",
      "|         for Beijing|\n",
      "|for Phillies game...|\n",
      "|    for symbioticket|\n",
      "|for Ameren: month #1|\n",
      "|for special skate...|\n",
      "|        for dog food|\n",
      "|        Weekend food|\n",
      "|  for CABBB BETCHHHH|\n",
      "|          for dinner|\n",
      "|for Sounders Tickets|\n",
      "|       for remainder|\n",
      "|              for ,,|\n",
      "|            ðŸ‘€\n",
      "ðŸ‘ƒ\n",
      "ðŸ‘…|\n",
      "|      for watermelon|\n",
      "|for LA Halloween ...|\n",
      "|       for mini food|\n",
      "|                Grim|\n",
      "|             Tickets|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This registers the dataframe as a table to make SQL queries on\n",
    "flat_df.registerTempTable('all_table')\n",
    "\n",
    "# we can treat the data as SQL and run queries!\n",
    "sqlContext.sql(\"SELECT message FROM all_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342281006"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+---------+\n",
      "|payment_id|             message|actor_id|target_id|\n",
      "+----------+--------------------+--------+---------+\n",
      "|    482374|             for tea|   59741|    33632|\n",
      "|    486539|    for contribution|  111497|   110891|\n",
      "|    486841|         for Beijing|   34421|    22792|\n",
      "|    462308|for Phillies game...|   85649|   107484|\n",
      "|    486850|    for symbioticket|   26924|    34907|\n",
      "|    550450|for Ameren: month #1|  115128|   115131|\n",
      "|    519086|for special skate...|   74104|    65588|\n",
      "|    559299|        for dog food|   71313|    60063|\n",
      "|    569537|        Weekend food|   29674|    22222|\n",
      "|    610826|  for CABBB BETCHHHH|  116523|   125011|\n",
      "|    612105|          for dinner|   73816|    27407|\n",
      "|    581179|for Sounders Tickets|   65739|    53702|\n",
      "|    571284|       for remainder|   28429|    43575|\n",
      "|    600315|              for ,,|  130287|   130290|\n",
      "|    615779|            ðŸ‘€\n",
      "ðŸ‘ƒ\n",
      "ðŸ‘…|  116185|   128330|\n",
      "|    689703|      for watermelon|  129335|   127245|\n",
      "|    630785|for LA Halloween ...|   63739|    64514|\n",
      "|    692091|       for mini food|  135785|    77747|\n",
      "|    635568|                Grim|  126429|   131328|\n",
      "|    752475|             Tickets|  126227|   123908|\n",
      "+----------+--------------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_df.select(\"payment_id\", \"message\", \"actor_id\", \"target_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------------+\n",
      "|max(payment_id)|max(target_id)|max(actor_id)|\n",
      "+---------------+--------------+-------------+\n",
      "|     1160228993|      41493705|     41493680|\n",
      "+---------------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_df.agg({\"payment_id\": \"max\", \"actor_id\": \"max\", \"target_id\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|payment_id|actor_num_friends|\n",
      "+----------+-----------------+\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_df.select(\"payment_id\", \"actor_num_friends\").filter(\"actor_num_friends > 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trans = flat_df.select(\"payment_id\", \"actor_id\").groupby(\"actor_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|actor_id|count|\n",
      "+--------+-----+\n",
      "|  116185|   31|\n",
      "|  118628|  507|\n",
      "|  502191|   53|\n",
      "|  242209|  181|\n",
      "|  225635|  313|\n",
      "|  152892|  118|\n",
      "|  573876|   34|\n",
      "|  744979|   48|\n",
      "| 1109864|   48|\n",
      "| 1136272|  129|\n",
      "|  215619|  131|\n",
      "| 1214786|   71|\n",
      "| 1327889|   17|\n",
      "|  437239|  173|\n",
      "|  534151|   32|\n",
      "|  536821|   59|\n",
      "|  475022|  222|\n",
      "|  657366|  186|\n",
      "| 1770597|  102|\n",
      "|  586616|  237|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_trans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12074276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_trans.filter(\"count < 10\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_trans.filter(\"count > 1000\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actor_id: long (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_trans.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|actor_id|min(unix_time)|\n",
      "+--------+--------------+\n",
      "|  116185|    1343703003|\n",
      "|  118628|    1338644689|\n",
      "|  502191|    1378346076|\n",
      "|  242209|    1364933796|\n",
      "|  225635|    1365375531|\n",
      "|  152892|    1350593125|\n",
      "|  573876|    1380405178|\n",
      "|  744979|    1386389879|\n",
      "| 1109864|    1395005831|\n",
      "| 1136272|    1395100090|\n",
      "|  215619|    1361037737|\n",
      "| 1214786|    1395510473|\n",
      "| 1327889|    1399590960|\n",
      "|  437239|    1377893394|\n",
      "|  534151|    1381653919|\n",
      "|  536821|    1390622884|\n",
      "|  475022|    1377566017|\n",
      "|  657366|    1383489906|\n",
      "| 1770597|    1404226464|\n",
      "|  586616|    1380857586|\n",
      "+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_df.groupby(\"actor_id\").agg({\"unix_time\": \"max\", \"unix_time\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+---------+\n",
      "|actor_id|newest_time|oldest_time| lifetime|\n",
      "+--------+-----------+-----------+---------+\n",
      "|  116185| 1418260027| 1343703003| 74557024|\n",
      "|  118628| 1533248917| 1338644689|194604228|\n",
      "|  502191| 1523150056| 1378346076|144803980|\n",
      "|  242209| 1520524433| 1364933796|155590637|\n",
      "|  225635| 1532999876| 1365375531|167624345|\n",
      "|  152892| 1533236117| 1350593125|182642992|\n",
      "|  573876| 1402376090| 1380405178| 21970912|\n",
      "|  744979| 1478725077| 1386389879| 92335198|\n",
      "| 1109864| 1514392872| 1395005831|119387041|\n",
      "| 1136272| 1524339991| 1395100090|129239901|\n",
      "|  215619| 1524068266| 1361037737|163030529|\n",
      "| 1214786| 1430752726| 1395510473| 35242253|\n",
      "| 1327889| 1467322535| 1399590960| 67731575|\n",
      "|  437239| 1502221230| 1377893394|124327836|\n",
      "|  534151| 1522565040| 1381653919|140911121|\n",
      "|  536821| 1524165607| 1390622884|133542723|\n",
      "|  475022| 1524416480| 1377566017|146850463|\n",
      "|  657366| 1523830853| 1383489906|140340947|\n",
      "| 1770597| 1523640332| 1404226464|119413868|\n",
      "|  586616| 1533364001| 1380857586|152506415|\n",
      "+--------+-----------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    " \n",
    "times = flat_df \\\n",
    "    .groupby(\"actor_id\") \\\n",
    "    .agg(fn.max(\"unix_time\").alias(\"newest_time\"), fn.min(\"unix_time\").alias(\"oldest_time\")) \\\n",
    "    .withColumn('lifetime', col('newest_time')-col('oldest_time'))\n",
    "\n",
    "times.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|actor_id|target_id|\n",
      "+--------+---------+\n",
      "|      29|       29|\n",
      "|    2453|     2453|\n",
      "|    3506|     3506|\n",
      "|   21209|    21209|\n",
      "|   29824|    29824|\n",
      "|   30928|    30928|\n",
      "|   32098|    32098|\n",
      "|   35253|    35253|\n",
      "|   37261|    37261|\n",
      "|   37884|    37884|\n",
      "|   38108|    38108|\n",
      "|   38510|    38510|\n",
      "|   38543|    38543|\n",
      "|   39094|    39094|\n",
      "|   39627|    39627|\n",
      "|   40132|    40132|\n",
      "|   41424|    41424|\n",
      "|   46424|    46424|\n",
      "|   47928|    47928|\n",
      "|   49048|    49048|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actors = flat_df.select(\"actor_id\").distinct()\n",
    "targets = flat_df.select(\"target_id\").distinct()\n",
    "\n",
    "actors_and_targets = actors.join(targets, actors.actor_id == targets.target_id)\n",
    "\n",
    "actors_and_targets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14494160"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inner Join count\n",
    "actors_and_targets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join count\n",
    "actors.join(targets, actors.actor_id == targets.target_id, how='left').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Join count\n",
    "actors.join(targets, actors.actor_id == targets.target_id, how='right').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Exclusive Join Count\n",
    "# Actors that are not ever targets\n",
    "actors.join(targets, actors.actor_id == targets.target_id, how='left') \\\n",
    "    .filter(\"target_id is null\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right Exclusive Join\n",
    "# Targets that are not ever actors\n",
    "actors.join(targets, actors.actor_id == targets.target_id, how='right') \\\n",
    "    .filter(\"actor_id is null\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all \n",
    "actors_plus_targets = actors.union(targets)\n",
    "\n",
    "actors_plus_targets.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_target = flat_df \\\n",
    "    .groupby(\"target_id\") \\\n",
    "    .agg(fn.max(\"unix_time\").alias(\"newest_time\"), fn.min(\"unix_time\").alias(\"oldest_time\")) \\\n",
    "    .withColumn('lifetime', col('newest_time')-col('oldest_time'))\n",
    "\n",
    "times_target.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = flat_df.select(\"actor_id\", col(\"actor_date_created\").alias(\"date_created\"))\n",
    "\n",
    "actors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.filter(\"actor_id == 59741\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "\n",
    "all_times = flat_df \\\n",
    "    .agg(fn.max(\"unix_time\").alias(\"newest_time\"), fn.min(\"unix_time\").alias(\"oldest_time\"))\n",
    "\n",
    "all_times.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Day: Sunday, March 25, 2012 1:01:35 AM GMT-05:00 DST\n",
    "\n",
    "Last Day: Thursday, August 16, 2018 1:05:47 AM GMT-05:00 DST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_k_path = '/data/06271/cju256/ten_k_flat.json'\n",
    "tenk_df = sqlContext.read.json(ten_k_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mil = flat_df.limit(1000000)\n",
    "one_mil.coalesce(1).write.format('json').save('/data/06271/cju256/one_mil.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
